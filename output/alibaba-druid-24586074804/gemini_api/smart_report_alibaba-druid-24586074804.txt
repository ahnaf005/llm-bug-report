**Bug Report**

---

**1. Title:** Build Failure: Checkstyle Violations in `IllegalSQLIndexFilter.java`

**2. Steps to Reproduce:**
1.  Checkout the codebase at commit SHA: `9003085f558c134de5b7fe70ac4d54e75898eae6`.
2.  Ensure Java Development Kit (JDK) version 17 is configured.
3.  Execute the Maven build command: `./mvnw -Penable-for-jdk17+,gen-code-cov clean package -B`

**3. Triggering Input:**
The presence of the file `src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java` containing specific formatting and coding style violations, which are detected by the `maven-checkstyle-plugin` during the build process.

**4. Expected Behavior:**
The Maven build should complete successfully, indicating that all code adheres to the defined Checkstyle rules and all compilation/packaging steps are passed.

**5. Observed Behavior:**
The Maven build fails during the `maven-checkstyle-plugin:3.1.2:check` goal for the `druid-parent` project. Nine Checkstyle violations are reported in `src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java`, leading to a `BUILD FAILURE`. Subsequent projects in the reactor build order are skipped.

**6. Relevant Code Snippets:**

The build log indicates the following Checkstyle violations in `src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java`:

```
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[34] (regexp) RegexpMultiline: Line has trailing whitespace
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[35] (regexp) RegexpMultiline: Line has trailing whitespace
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[42] (regexp) RegexpMultiline: Line has trailing whitespace
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[49] (regexp) RegexpMultiline: Blank line after opening brace
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[83,51] (whitespace) WhitespaceAround: ':' is not preceded with whitespace.
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[96,51] (whitespace) WhitespaceAround: ':' is not preceded with whitespace.
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[107,66] (coding) EmptyStatement: Empty statement.
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[117,45] (whitespace) WhitespaceAround: ':' is not preceded with whitespace.
[ERROR] src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java:[177] (regexp) RegexpMultiline: Blank line after opening brace
```

The code diff shows that the problematic file `src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java` was entirely deleted:

```diff
--- a/src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java
+++ /dev/null
@@ -1,210 +0,0 @@
-package com.alibaba.druid.filter.index;
-... (210 lines deleted)
```

**7. Stack Traces:**

The build log provides the following error summary from the Maven Checkstyle plugin:

```
2024-05-04T12:44:30.9140051Z [INFO] ------------------------------------------------------------------------
2024-05-04T12:44:30.9140743Z [INFO] Reactor Summary:
2024-05-04T12:44:30.9141170Z [INFO] 
2024-05-04T12:44:30.9142265Z [INFO] druid-parent 1.2.23-SNAPSHOT ....................... FAILURE [  1.732 s]
2024-05-04T12:44:30.9143395Z [INFO] druid 1.2.23-SNAPSHOT .............................. SKIPPED
2024-05-04T12:44:30.9144430Z [INFO] druid-spring-boot-starter 1.2.23-SNAPSHOT .......... SKIPPED
2024-05-04T12:44:30.9145503Z [INFO] druid-wrapper 1.2.23-SNAPSHOT ...................... SKIPPED
2024-05-04T12:44:30.9146567Z [INFO] druid-demo-petclinic 2.7.18 ........................ SKIPPED
2024-05-04T12:44:30.9147633Z [INFO] druid-spring-boot-3-starter 1.2.23-SNAPSHOT ........ SKIPPED
2024-05-04T12:44:30.9148655Z [INFO] ------------------------------------------------------------------------
2024-05-04T12:44:30.9149354Z [INFO] BUILD FAILURE
2024-05-04T12:44:30.9150030Z [INFO] ------------------------------------------------------------------------
2024-05-04T12:44:30.9177811Z [ERROR] Failed to execute goal org.apache.maven.plugins:maven-checkstyle-plugin:3.1.2:check (checkstyle) on project druid-parent: You have 9 Checkstyle violations. -> [Help 1]
```

**8. Patches / Suggested Fixes:**

The provided code diff indicates the following changes were made to resolve the build failure and address related issues:

1.  **Deletion of `IllegalSQLIndexFilter.java` and its test:** The file `src/main/java/com/alibaba/druid/filter/index/IllegalSQLIndexFilter.java` (210 lines) and its corresponding test file `src/test/java/com/alibaba/druid/bvt/filter/IllegalSQLIndexFilterExecuteTest.java` (100 lines) were completely removed. This directly resolves the Checkstyle violations by eliminating the source of the errors.

2.  **Reordering of `SORTED BY` and `INTO BUCKETS` clauses in `SQLASTOutputVisitor.java`:**
    The `sortedBy` and `buckets` output logic was moved to appear before `serdeProperties` in the `SQLASTOutputVisitor` class. This suggests a fix for an incorrect output order when generating Hive SQL `CREATE TABLE` statements.
    ```diff
    --- a/core/src/main/java/com/alibaba/druid/sql/visitor/SQLASTOutputVisitor.java
    +++ b/core/src/main/java/com/alibaba/druid/sql/visitor/SQLASTOutputVisitor.java
    @@ -10962,7 +10962,20 @@ public class SQLASTOutputVisitor extends SQLASTVisitorAdapter implements Paramet
                 printAndAccept(clusteredBy, ",");
                 print(')');
             }
    -
    +        List<SQLSelectOrderByItem> sortedBy = x.getSortedBy();
    +        if (sortedBy.size() > 0) {
    +            println();
    +            print0(ucase ? "SORTED BY (" : "sorted by (");
    +            printAndAccept(sortedBy, ", ");
    +            print(')');
    +        }
    +        int buckets = x.getBuckets();
    +        if (buckets > 0) {
    +            println();
    +            print0(ucase ? "INTO " : "into ");
    +            print(buckets);
    +            print0(ucase ? " BUCKETS" : " buckets");
    +        }
             List<SQLExpr> skewedBy = x.getSkewedBy();
             if (skewedBy.size() > 0) {
                 println();
    @@ -10987,26 +11000,8 @@ public class SQLASTOutputVisitor extends SQLASTVisitorAdapter implements Paramet
                 }
                 visit(format);
             }
    -
             Map<String, SQLObject> serdeProperties = x.getSerdeProperties();
             printSerdeProperties(serdeProperties);
    -
    -        List<SQLSelectOrderByItem> sortedBy = x.getSortedBy();
    -        if (sortedBy.size() > 0) {
    -            println();
    -            print0(ucase ? "SORTED BY (" : "sorted by (");
    -            printAndAccept(sortedBy, ", ");
    -            print(')');
    -        }
    -
    -        int buckets = x.getBuckets();
    -        if (buckets > 0) {
    -            println();
    -            print0(ucase ? "INTO " : "into ");
    -            print(buckets);
    -            print0(ucase ? " BUCKETS" : " buckets");
    -        }
    -
             SQLExprTableSource like = x.getLike();
             if (like != null) {
                 println();
    ```

3.  **Update to `HiveCreateTableTest_12.java`:** The expected output in a test case was adjusted to reflect the new order of `SORTED BY` and `INTO BUCKETS` clauses, confirming the change in `SQLASTOutputVisitor.java`.
    ```diff
    --- a/core/src/test/java/com/alibaba/druid/bvt/sql/hive/HiveCreateTableTest_12.java
    +++ b/core/src/test/java/com/alibaba/druid/bvt/sql/hive/HiveCreateTableTest_12.java
    @@ -64,12 +64,12 @@ public class HiveCreateTableTest_12 extends OracleTest {
                         "\tcountry STRING\n" +\
                         ")\n" +\
                         "CLUSTERED BY (userid)\n" +\
    +                    "SORTED BY (viewTime)\n" +\
    +                    "INTO 32 BUCKETS\n" +\
                         "ROW FORMAT DELIMITED\n" +\
                         "\tFIELDS TERMINATED BY '\\001'\n" +\
                         "\tCOLLECTION ITEMS TERMINATED BY '\\002'\n" +\
                         "\tMAP KEYS TERMINATED BY '\\003'\n" +\
    -                    "SORTED BY (viewTime)\n" +\
    -                    "INTO 32 BUCKETS\n" +\
                         "STORED AS SEQUENCEFILE;", text);
             }
     
    ```

4.  **Addition of `Issue5853.java`:** A new test file was added to specifically test Hive `CREATE TABLE` parsing and output for various scenarios, including `CLUSTERED BY`, `SORTED BY`, and `INTO BUCKETS` clauses. This new test suite validates the correctness of the Hive SQL parsing and formatting logic.
    ```diff
    --- /dev/null
    +++ b/core/src/test/java/com/alibaba/druid/bvt/sql/hive/issues/Issue5853.java
    @@ -0,0 +1,91 @@
    +package com.alibaba.druid.bvt.sql.hive.issues;
    +
    +import java.util.List;
    +
    +import com.alibaba.druid.DbType;
    +import com.alibaba.druid.sql.ast.SQLStatement;
    +import com.alibaba.druid.sql.parser.SQLParserUtils;
    +import com.alibaba.druid.sql.parser.SQLStatementParser;
    +
    +import org.junit.Test;
    +
    +import static org.junit.Assert.assertEquals;
    +
    +/**
    + * Hive解析CREATE TABLE的问题
    + *
    + * @see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">...</a>
    + */
    +public class Issue5853 {
    +
    +    @Test
    +    public void test_parse_create_0() {
    +        for (String sql : new String[]{
    +            "CREATE TABLE page_view (\n"
    +                + "\tviewTime INT,\n"
    +                + "\tuserid BIGINT,\n"
    +                + "\tpage_url STRING,\n"
    +                + "\treferrer_url STRING,\n"
    +                + "\tip STRING COMMENT 'IP Address of the User'\n"
    +                + ")\n"
    +                + "COMMENT 'This is the page view table'\n"
    +                + "PARTITIONED BY (\n"
    +                + "\tdt STRING,\n"
    +                + "\tcountry STRING\n"
    +                + ")\n"
    +                + "CLUSTERED BY (userid)\n"
    +                + "SORTED BY (viewTime)\n"
    +                + "INTO 32 BUCKETS\n"
    +                + "ROW FORMAT DELIMITED\n"
    +                + "\tFIELDS TERMINATED BY '\\001'\n"
    +                + "\tCOLLECTION ITEMS TERMINATED BY '\\002'\n"
    +                + "\tMAP KEYS TERMINATED BY '\\003'\n"
    +                + "STORED AS SEQUENCEFILE;",
    +        }) {
    +            System.out.println("原始的sql===" + sql);
    +            SQLStatementParser parser1 = SQLParserUtils.createSQLStatementParser(sql, DbType.hive);
    +            List<SQLStatement> statementList1 = parser1.parseStatementList();
    +            String sqleNew = statementList1.get(0).toString();
    +            System.out.println("生成的sql===" + sqleNew);
    +            assertEquals(sql, sqleNew);
    +            SQLStatementParser parser2 = SQLParserUtils.createSQLStatementParser(sqleNew, DbType.hive);
    +            List<SQLStatement> statementList2 = parser2.parseStatementList();
    +            String sqleNew2 = statementList2.get(0).toString();
    +            System.out.println("再次解析生成的sql===" + sqleNew2);
    +            assertEquals(sqleNew, sqleNew2);
    +        }
    +
    +    }
    +
    +    @Test
    +    public void test_parse_create_1() {
    +        for (String sql : new String[]{
    +            "CREATE TABLE db.route(\n"
    +                + "od_id string COMMENT 'OD',\n"
    +                + "data_dt string COMMENT 'data date')\n"
    +                + "CLUSTERED BY (\n"
    +                + "od_id)\n"
    +                + "INTO 8 BUCKETS\n"
    +                + "ROW FORMAT SERDE\n"
    +                + "'org.apache.hadoop.hive.ql.io.orc.OrcSerde'\n"
    +                + "STORED AS INPUTFORMAT\n"
    +                + "'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'\n"
    +                + "OUTPUTFORMAT\n"
    +                + "'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat';",
    +
    +        }) {
    +            System.out.println("原始的sql===" + sql);
    +            SQLStatementParser parser1 = SQLParserUtils.createSQLStatementParser(sql, DbType.hive);
    +            List<SQLStatement> statementList1 = parser1.parseStatementList();
    +            String sqleNew = statementList1.get(0).toString();
    +            System.out.println("生成的sql===" + sqleNew);
    +            SQLStatementParser parser2 = SQLParserUtils.createSQLStatementParser(sqleNew, DbType.hive);
    +            List<SQLStatement> statementList2 = parser2.parseStatementList();
    +            String sqleNew2 = statementList2.get(0).toString();
    +            System.out.println("再次解析生成的sql===" + sqleNew2);
    +            assertEquals(sqleNew, sqleNew2);
    +        }
    +
    +    }
    +
    +}
    ```